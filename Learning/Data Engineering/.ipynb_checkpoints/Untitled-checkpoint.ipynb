{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ea4b38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "json_objects = []\n",
    "input_file_path = '/Users/alsidhu/Downloads/archive/JSONL/yelp_academic_dataset_tip.json'\n",
    "output_file_path = '/Users/alsidhu/Downloads/archive/JSON/yelp_academic_dataset_tip.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65ff1f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted JSONL to JSON array and assigned to 'data' element in /Users/alsidhu/Downloads/archive/JSON/yelp_academic_dataset_tip.json\n"
     ]
    }
   ],
   "source": [
    "with open(input_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Parse each line as a JSON object and append it to the list\n",
    "        try:\n",
    "            json_obj = json.loads(line)\n",
    "            json_objects.append(json_obj)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Skipping invalid JSON line: {line.strip()}\")\n",
    "\n",
    "# Convert the list of JSON objects to a JSON array\n",
    "json_array = json.dumps(json_objects, separators=(',', ':'))  # Remove indentation\n",
    "\n",
    "# Create a JSON object with the 'data' key and the JSON array as its value\n",
    "json_object = {\n",
    "    \"tip_data\": json.loads(json_array)\n",
    "}\n",
    "\n",
    "# Replace 'output.json' with the desired output file path\n",
    "\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    json.dump(json_object, output_file, separators=(',', ':'))\n",
    "\n",
    "print(f\"Converted JSONL to JSON array and assigned to 'data' element in {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f927d198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split JSONL into JSON objects with 302971 records per object and saved to /Users/alsidhu/Downloads/archive/JSON/yelp_academic_dataset_tip.json\n"
     ]
    }
   ],
   "source": [
    "## TIP\n",
    "import json\n",
    "import os\n",
    "json_objects = []\n",
    "input_file_path = '/Users/alsidhu/Downloads/archive/JSONL/yelp_academic_dataset_tip.json'\n",
    "output_file_path = '/Users/alsidhu/Downloads/archive/JSON/yelp_academic_dataset_tip.json'\n",
    "batch_size = 302971\n",
    "with open(input_file_path, 'r') as input_file:\n",
    "    for line in input_file:\n",
    "        # Parse each line as a JSON object and append it to the list\n",
    "        try:\n",
    "            json_obj = json.loads(line)\n",
    "            json_objects.append(json_obj)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Skipping invalid JSON line: {line.strip()}\")\n",
    "\n",
    "        # Check if we've reached the batch size\n",
    "        if len(json_objects) == batch_size:\n",
    "            # Create a JSON object with the 'data' key and the list of JSON objects\n",
    "            json_object = {\"data\": json_objects}\n",
    "\n",
    "            # Write the JSON object to the output file as a single-line JSONL record\n",
    "            with open(output_file_path, 'a') as output_file:\n",
    "                output_file.write(json.dumps(json_object) + '\\n')\n",
    "\n",
    "            # Clear the list for the next batch\n",
    "            json_objects = []\n",
    "\n",
    "# Check if there are any remaining JSON objects to write\n",
    "if json_objects:\n",
    "    # Create a JSON object with the 'data' key and the list of remaining JSON objects\n",
    "    json_object = {\"data\": json_objects}\n",
    "\n",
    "    # Write the remaining JSON object to the output file as a single-line JSONL record\n",
    "    with open(output_file_path, 'a') as output_file:\n",
    "        output_file.write(json.dumps(json_object) + '\\n')\n",
    "\n",
    "print(f\"Split JSONL into JSON objects with {batch_size} records per object and saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6cd1407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split JSONL into JSON objects with 100000 records per object and saved to /Users/alsidhu/Downloads/archive/JSON/yelp_academic_dataset_business.json\n"
     ]
    }
   ],
   "source": [
    "## BUSINESS\n",
    "import json\n",
    "import os\n",
    "json_objects = []\n",
    "input_file_path = '/Users/alsidhu/Downloads/archive/JSONL/yelp_academic_dataset_business.json'\n",
    "output_file_path = '/Users/alsidhu/Downloads/archive/JSON/yelp_academic_dataset_business.json'\n",
    "batch_size = 100000\n",
    "with open(input_file_path, 'r') as input_file:\n",
    "    for line in input_file:\n",
    "        # Parse each line as a JSON object and append it to the list\n",
    "        try:\n",
    "            json_obj = json.loads(line)\n",
    "            json_objects.append(json_obj)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Skipping invalid JSON line: {line.strip()}\")\n",
    "\n",
    "        # Check if we've reached the batch size\n",
    "        if len(json_objects) == batch_size:\n",
    "            # Create a JSON object with the 'data' key and the list of JSON objects\n",
    "            json_object = {\"data\": json_objects}\n",
    "\n",
    "            # Write the JSON object to the output file as a single-line JSONL record\n",
    "            with open(output_file_path, 'a') as output_file:\n",
    "                output_file.write(json.dumps(json_object) + '\\n')\n",
    "\n",
    "            # Clear the list for the next batch\n",
    "            json_objects = []\n",
    "\n",
    "# Check if there are any remaining JSON objects to write\n",
    "if json_objects:\n",
    "    # Create a JSON object with the 'data' key and the list of remaining JSON objects\n",
    "    json_object = {\"data\": json_objects}\n",
    "\n",
    "    # Write the remaining JSON object to the output file as a single-line JSONL record\n",
    "    with open(output_file_path, 'a') as output_file:\n",
    "        output_file.write(json.dumps(json_object) + '\\n')\n",
    "\n",
    "print(f\"Split JSONL into JSON objects with {batch_size} records per object and saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f86e757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split JSONL into JSON objects with 33000 records per object and saved to /Users/alsidhu/Downloads/archive/JSON/yelp_academic_dataset_checkin.json\n"
     ]
    }
   ],
   "source": [
    "## CHECKIN\n",
    "import json\n",
    "import os\n",
    "json_objects = []\n",
    "input_file_path = '/Users/alsidhu/Downloads/archive/JSONL/yelp_academic_dataset_checkin.json'\n",
    "output_file_path = '/Users/alsidhu/Downloads/archive/JSON/yelp_academic_dataset_checkin.json'\n",
    "batch_size = 33000\n",
    "with open(input_file_path, 'r') as input_file:\n",
    "    for line in input_file:\n",
    "        # Parse each line as a JSON object and append it to the list\n",
    "        try:\n",
    "            json_obj = json.loads(line)\n",
    "            json_objects.append(json_obj)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Skipping invalid JSON line: {line.strip()}\")\n",
    "\n",
    "        # Check if we've reached the batch size\n",
    "        if len(json_objects) == batch_size:\n",
    "            # Create a JSON object with the 'data' key and the list of JSON objects\n",
    "            json_object = {\"data\": json_objects}\n",
    "\n",
    "            # Write the JSON object to the output file as a single-line JSONL record\n",
    "            with open(output_file_path, 'a') as output_file:\n",
    "                output_file.write(json.dumps(json_object) + '\\n')\n",
    "\n",
    "            # Clear the list for the next batch\n",
    "            json_objects = []\n",
    "\n",
    "# Check if there are any remaining JSON objects to write\n",
    "if json_objects:\n",
    "    # Create a JSON object with the 'data' key and the list of remaining JSON objects\n",
    "    json_object = {\"data\": json_objects}\n",
    "\n",
    "    # Write the remaining JSON object to the output file as a single-line JSONL record\n",
    "    with open(output_file_path, 'a') as output_file:\n",
    "        output_file.write(json.dumps(json_object) + '\\n')\n",
    "\n",
    "print(f\"Split JSONL into JSON objects with {batch_size} records per object and saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "31469667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split JSONL into JSON objects with 30000 records per object and saved to /Users/alsidhu/Downloads/archive/JSON/yelp_academic_dataset_user2.json\n"
     ]
    }
   ],
   "source": [
    "## Users | 1987897\n",
    "import json\n",
    "import os\n",
    "json_objects = []\n",
    "input_file_path = '/Users/alsidhu/Downloads/archive/JSONL/yelp_academic_dataset_user.json'\n",
    "output_file_path = '/Users/alsidhu/Downloads/archive/JSON/yelp_academic_dataset_user2.json'\n",
    "batch_size = 30000\n",
    "with open(input_file_path, 'r') as input_file:\n",
    "    for line in input_file:\n",
    "        # Parse each line as a JSON object and append it to the list\n",
    "        try:\n",
    "            json_obj = json.loads(line)\n",
    "            json_objects.append(json_obj)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Skipping invalid JSON line: {line.strip()}\")\n",
    "\n",
    "        # Check if we've reached the batch size\n",
    "        if len(json_objects) == batch_size:\n",
    "            # Create a JSON object with the 'data' key and the list of JSON objects\n",
    "            json_object = {\"data\": json_objects}\n",
    "\n",
    "            # Write the JSON object to the output file as a single-line JSONL record\n",
    "            with open(output_file_path, 'a') as output_file:\n",
    "                output_file.write(json.dumps(json_object) + '\\n')\n",
    "\n",
    "            # Clear the list for the next batch\n",
    "            json_objects = []\n",
    "\n",
    "# Check if there are any remaining JSON objects to write\n",
    "if json_objects:\n",
    "    # Create a JSON object with the 'data' key and the list of remaining JSON objects\n",
    "    json_object = {\"data\": json_objects}\n",
    "\n",
    "    # Write the remaining JSON object to the output file as a single-line JSONL record\n",
    "    with open(output_file_path, 'a') as output_file:\n",
    "        output_file.write(json.dumps(json_object) + '\\n')\n",
    "\n",
    "print(f\"Split JSONL into JSON objects with {batch_size} records per object and saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e306810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split JSONL into JSON objects with 100000 records per object and saved to /Users/alsidhu/Downloads/archive/JSON/yelp_academic_dataset_review.json\n"
     ]
    }
   ],
   "source": [
    "## REVIEW | 6990280\n",
    "import json\n",
    "import os\n",
    "json_objects = []\n",
    "input_file_path = '/Users/alsidhu/Downloads/archive/JSONL/yelp_academic_dataset_review.json'\n",
    "output_file_path = '/Users/alsidhu/Downloads/archive/JSON/yelp_academic_dataset_review.json'\n",
    "batch_size = 100000\n",
    "with open(input_file_path, 'r') as input_file:\n",
    "    for line in input_file:\n",
    "        # Parse each line as a JSON object and append it to the list\n",
    "        try:\n",
    "            json_obj = json.loads(line)\n",
    "            json_objects.append(json_obj)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Skipping invalid JSON line: {line.strip()}\")\n",
    "\n",
    "        # Check if we've reached the batch size\n",
    "        if len(json_objects) == batch_size:\n",
    "            # Create a JSON object with the 'data' key and the list of JSON objects\n",
    "            json_object = {\"data\": json_objects}\n",
    "\n",
    "            # Write the JSON object to the output file as a single-line JSONL record\n",
    "            with open(output_file_path, 'a') as output_file:\n",
    "                output_file.write(json.dumps(json_object) + '\\n')\n",
    "\n",
    "            # Clear the list for the next batch\n",
    "            json_objects = []\n",
    "\n",
    "# Check if there are any remaining JSON objects to write\n",
    "if json_objects:\n",
    "    # Create a JSON object with the 'data' key and the list of remaining JSON objects\n",
    "    json_object = {\"data\": json_objects}\n",
    "\n",
    "    # Write the remaining JSON object to the output file as a single-line JSONL record\n",
    "    with open(output_file_path, 'a') as output_file:\n",
    "        output_file.write(json.dumps(json_object) + '\\n')\n",
    "\n",
    "print(f\"Split JSONL into JSON objects with {batch_size} records per object and saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e23762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
